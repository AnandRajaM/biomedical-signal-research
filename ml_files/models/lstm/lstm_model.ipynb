{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mboredxmc\u001b[0m (\u001b[33mboredxmc-school\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\24phd7039\\biomedical-research\\ml_files\\models\\lstm\\wandb\\run-20250120_091045-aqn6yfjq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/boredxmc-school/t14/runs/aqn6yfjq' target=\"_blank\">deft-surf-2</a></strong> to <a href='https://wandb.ai/boredxmc-school/t14' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/boredxmc-school/t14' target=\"_blank\">https://wandb.ai/boredxmc-school/t14</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/boredxmc-school/t14/runs/aqn6yfjq' target=\"_blank\">https://wandb.ai/boredxmc-school/t14/runs/aqn6yfjq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/boredxmc-school/t14/runs/aqn6yfjq?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1989140f1a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from torchviz import make_dot\n",
    "\n",
    "# projects t1-t14 (main : project-lstm)\n",
    "wandb.init(project=\"t14\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: 79175 samples\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------\n",
    "# Load & process data\n",
    "# ----------------------------------\n",
    "file_path = r'train.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df = df.iloc[:len(df)//16]\n",
    "\n",
    "seq_len = 2000\n",
    "input_features = 2  # radar_i, radar_q\n",
    "output_features = 1  # tfm_ecg2\n",
    "\n",
    "data = df.values.astype(np.float32)\n",
    "X = np.array([data[i:i+seq_len, :input_features] for i in range(len(data) - seq_len)])\n",
    "y = data[seq_len:, input_features:input_features+output_features]\n",
    "\n",
    "X_tensor = torch.tensor(X)\n",
    "y_tensor = torch.tensor(y)\n",
    "\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "batch_size =  100\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Loaded dataset: {len(dataset)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# Model\n",
    "# ----------------------------------\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    # Model Struct \n",
    "    # LSTM -> FC\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hidden_size = 100\n",
    "num_layers = 4\n",
    "learning_rate = 0.0001\n",
    "epochs = 10\n",
    "\n",
    "model = LSTMModel(input_features, hidden_size, output_features, num_layers).to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "wandb.watch(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Batch [1/792], Loss: 0.1709\n",
      "Epoch [1/10], Batch [101/792], Loss: 0.0034\n",
      "Epoch [1/10], Batch [201/792], Loss: 0.0663\n",
      "Epoch [1/10], Batch [301/792], Loss: 0.0070\n",
      "Epoch [1/10], Batch [401/792], Loss: 0.0083\n",
      "Epoch [1/10], Batch [501/792], Loss: 0.0209\n",
      "Epoch [1/10], Batch [601/792], Loss: 0.0091\n",
      "Epoch [1/10], Batch [701/792], Loss: 0.0039\n",
      "Epoch [1/10] Loss: 0.0714\n",
      "Epoch [2/10], Batch [1/792], Loss: 0.1128\n",
      "Epoch [2/10], Batch [101/792], Loss: 0.0011\n",
      "Epoch [2/10], Batch [201/792], Loss: 0.0641\n",
      "Epoch [2/10], Batch [301/792], Loss: 0.0092\n",
      "Epoch [2/10], Batch [401/792], Loss: 0.0052\n",
      "Epoch [2/10], Batch [501/792], Loss: 0.0243\n",
      "Epoch [2/10], Batch [601/792], Loss: 0.0115\n",
      "Epoch [2/10], Batch [701/792], Loss: 0.0028\n",
      "Epoch [2/10] Loss: 0.0572\n",
      "Epoch [3/10], Batch [1/792], Loss: 0.0155\n",
      "Epoch [3/10], Batch [101/792], Loss: 0.0021\n",
      "Epoch [3/10], Batch [201/792], Loss: 0.0347\n",
      "Epoch [3/10], Batch [301/792], Loss: 0.0067\n",
      "Epoch [3/10], Batch [401/792], Loss: 0.0037\n",
      "Epoch [3/10], Batch [501/792], Loss: 0.0017\n",
      "Epoch [3/10], Batch [601/792], Loss: 0.0083\n",
      "Epoch [3/10], Batch [701/792], Loss: 0.0103\n",
      "Epoch [3/10] Loss: 0.0528\n",
      "Epoch [4/10], Batch [1/792], Loss: 0.0146\n",
      "Epoch [4/10], Batch [101/792], Loss: 0.0015\n",
      "Epoch [4/10], Batch [201/792], Loss: 0.0325\n",
      "Epoch [4/10], Batch [301/792], Loss: 0.0078\n",
      "Epoch [4/10], Batch [401/792], Loss: 0.0069\n",
      "Epoch [4/10], Batch [501/792], Loss: 0.0024\n",
      "Epoch [4/10], Batch [601/792], Loss: 0.0126\n",
      "Epoch [4/10], Batch [701/792], Loss: 0.0039\n",
      "Epoch [4/10] Loss: 0.0512\n",
      "Epoch [5/10], Batch [1/792], Loss: 0.0123\n",
      "Epoch [5/10], Batch [101/792], Loss: 0.0024\n",
      "Epoch [5/10], Batch [201/792], Loss: 0.0179\n",
      "Epoch [5/10], Batch [301/792], Loss: 0.0088\n",
      "Epoch [5/10], Batch [401/792], Loss: 0.0030\n",
      "Epoch [5/10], Batch [501/792], Loss: 0.0012\n",
      "Epoch [5/10], Batch [601/792], Loss: 0.0111\n",
      "Epoch [5/10], Batch [701/792], Loss: 0.0027\n",
      "Epoch [5/10] Loss: 0.0514\n",
      "Epoch [6/10], Batch [1/792], Loss: 0.0121\n",
      "Epoch [6/10], Batch [101/792], Loss: 0.0031\n",
      "Epoch [6/10], Batch [201/792], Loss: 0.0131\n",
      "Epoch [6/10], Batch [301/792], Loss: 0.0076\n",
      "Epoch [6/10], Batch [401/792], Loss: 0.0070\n",
      "Epoch [6/10], Batch [501/792], Loss: 0.0023\n",
      "Epoch [6/10], Batch [601/792], Loss: 0.0154\n",
      "Epoch [6/10], Batch [701/792], Loss: 0.0127\n",
      "Epoch [6/10] Loss: 0.0509\n",
      "Epoch [7/10], Batch [1/792], Loss: 0.0110\n",
      "Epoch [7/10], Batch [101/792], Loss: 0.0010\n",
      "Epoch [7/10], Batch [201/792], Loss: 0.0068\n",
      "Epoch [7/10], Batch [301/792], Loss: 0.0105\n",
      "Epoch [7/10], Batch [401/792], Loss: 0.0052\n",
      "Epoch [7/10], Batch [501/792], Loss: 0.0021\n",
      "Epoch [7/10], Batch [601/792], Loss: 0.0132\n",
      "Epoch [7/10], Batch [701/792], Loss: 0.0013\n",
      "Epoch [7/10] Loss: 0.0499\n",
      "Epoch [8/10], Batch [1/792], Loss: 0.0106\n",
      "Epoch [8/10], Batch [101/792], Loss: 0.0009\n",
      "Epoch [8/10], Batch [201/792], Loss: 0.0039\n",
      "Epoch [8/10], Batch [301/792], Loss: 0.0094\n",
      "Epoch [8/10], Batch [401/792], Loss: 0.0041\n",
      "Epoch [8/10], Batch [501/792], Loss: 0.0012\n",
      "Epoch [8/10], Batch [601/792], Loss: 0.0092\n",
      "Epoch [8/10], Batch [701/792], Loss: 0.0072\n",
      "Epoch [8/10] Loss: 0.0497\n",
      "Epoch [9/10], Batch [1/792], Loss: 0.0108\n",
      "Epoch [9/10], Batch [101/792], Loss: 0.0009\n",
      "Epoch [9/10], Batch [201/792], Loss: 0.0020\n",
      "Epoch [9/10], Batch [301/792], Loss: 0.0078\n",
      "Epoch [9/10], Batch [401/792], Loss: 0.0050\n",
      "Epoch [9/10], Batch [501/792], Loss: 0.0011\n",
      "Epoch [9/10], Batch [601/792], Loss: 0.0116\n",
      "Epoch [9/10], Batch [701/792], Loss: 0.0023\n",
      "Epoch [9/10] Loss: 0.0491\n",
      "Epoch [10/10], Batch [1/792], Loss: 0.0108\n",
      "Epoch [10/10], Batch [101/792], Loss: 0.0009\n",
      "Epoch [10/10], Batch [201/792], Loss: 0.0030\n",
      "Epoch [10/10], Batch [301/792], Loss: 0.0078\n",
      "Epoch [10/10], Batch [401/792], Loss: 0.0053\n",
      "Epoch [10/10], Batch [501/792], Loss: 0.0014\n",
      "Epoch [10/10], Batch [601/792], Loss: 0.0111\n",
      "Epoch [10/10], Batch [701/792], Loss: 0.0066\n",
      "Epoch [10/10] Loss: 0.0487\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------\n",
    "# Training and evaluation\n",
    "# ----------------------------------\n",
    "def train_model(model, train_loader, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)   #use gpu\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(inputs)\n",
    "            loss = loss_fn(predictions, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            wandb.log({\"Batch Loss\": loss.item()})\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "        wandb.log({\"Epoch Loss\": avg_epoch_loss})\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "model = train_model(model, train_loader, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n",
      "Evaluation Loss: 0.0657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06571679511361796"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------\n",
    "# Save and evaluate model\n",
    "# ----------------------------------\n",
    "\n",
    "torch.save(model.state_dict(), \"lstm_model.pth\")\n",
    "print(\"Model saved.\")\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            predictions = model(inputs)\n",
    "            loss = loss_fn(predictions, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    print(f\"Evaluation Loss: {avg_loss:.4f}\")\n",
    "    wandb.log({\"Evaluation Loss\": avg_loss})\n",
    "    return avg_loss\n",
    "\n",
    "evaluate_model(model, train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions vs. actuals to predicted_vs_actual.csv\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------\n",
    "# Save predictions (GDN0009 used)\n",
    "# ----------------------------------\n",
    "\n",
    "\n",
    "def evaluate_and_save(model, data_loader, csv_path=\"predicted_vs_actual.csv\"):\n",
    "    model.eval()\n",
    "    predictions_list = []\n",
    "    actual_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            predictions = model(inputs)\n",
    "            predictions_list.append(predictions.cpu().numpy())\n",
    "            actual_list.append(targets.cpu().numpy())\n",
    "\n",
    "    predictions_array = np.concatenate(predictions_list, axis=0)\n",
    "    actual_array = np.concatenate(actual_list, axis=0)\n",
    "    df = pd.DataFrame({\n",
    "        \"Predicted\": predictions_array.flatten(),\n",
    "        \"Actual\": actual_array.flatten()\n",
    "    })\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved predictions vs. actuals to {csv_path}\")\n",
    "    return df\n",
    "\n",
    "predicted_vs_actual_df = evaluate_and_save(model, train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture plot saved as lstm_model_architecture.png\n"
     ]
    }
   ],
   "source": [
    "sample_input = torch.randn(1, seq_len, input_features).to(device)\n",
    "output = model(sample_input)\n",
    "\n",
    "dot = make_dot(output, params=dict(model.named_parameters()))\n",
    "dot.render(\"lstm_model_architecture\", format=\"png\")\n",
    "print(\"Model architecture plot saved as lstm_model_architecture.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to D:\\24phd7039\\biomedical-research\\ml_files\\utils\\plot_folder\\GDN0003\\combined.csv\n"
     ]
    }
   ],
   "source": [
    "def replace_and_save_predictions(model, original_csv_path, output_csv_path):\n",
    "    model.eval()\n",
    "\n",
    "    df = pd.read_csv(original_csv_path)\n",
    "    data = df.values.astype(np.float32)\n",
    "    \n",
    "    seq_len = 100\n",
    "    input_features = 2  # radar_i, radar_q\n",
    "    output_features = 1  # tfm_ecg2\n",
    "\n",
    "    X = np.array([data[i:i+seq_len, :input_features] for i in range(len(data) - seq_len)])\n",
    "    X_tensor = torch.tensor(X).to(device)\n",
    "\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(X_tensor), batch_size):\n",
    "            batch_input = X_tensor[i:i+batch_size]\n",
    "            batch_predictions = model(batch_input)\n",
    "            predictions.append(batch_predictions.cpu().numpy())\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    new_tfm_ecg2 = np.full((len(data),), np.nan, dtype=np.float32)\n",
    "    new_tfm_ecg2[seq_len:] = predictions.flatten()\n",
    "\n",
    "    df.iloc[:, input_features] = new_tfm_ecg2\n",
    "\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Updated CSV saved to {output_csv_path}\")\n",
    "\n",
    "# Replaacing the tfm_ecg2 values in the original csv file with the predicted values\n",
    "original_csv_path = r'original.csv'\n",
    "output_csv_path = r'updated.csv'\n",
    "replace_and_save_predictions(model, original_csv_path, output_csv_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
